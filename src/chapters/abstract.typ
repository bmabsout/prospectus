= Abstract

This dissertation research introduces and addresses the intent-to-reality gap in robot learningâ€”the challenge of translating high-level intentions into deployable policies. Practitioners face two key obstacles: expressing their intentions as learning objectives (the intent-to-behavior gap) and maintaining policy behavior when moving from simulation to reality (the sim-to-real gap). Current approaches lack principled structure for specifying objectives and rely on optimization targets that break down during transfer, leading to catastrophic forgetting when policies fail to preserve learned behaviors.

I introduce Expressive Reinforcement Learning as a subfield focused on minimizing the intent-to-behavior gap through structured objective specification and composition. My early work demonstrated the promise of this design space by developing RE+AL, the first reinforcement learning framework to outperform classical PID controllers on quadrotor attitude control. Countless hours wrestling with brittle reward functions and watching otherwise-promising policies fail in spectacular ways taught me the need for more principled foundations. This led to the focus around objective specification and composition through which many methods were developed such as: (1) Conditioning for Action Policy Smoothness, allowing a robot actuating in reality to reduce its power consumption by 80% while maintaining good performance, (2) anchor critics for preventing catastrophic forgetting during sim-to-real transfer, and (3) an Algebraic Q-value Scalarization (AQS) method that minimizes the intent-to-behavior gap through intuitive objective composition producing a 600% improvement in sample efficiency. Through validation on increasingly complex robotic systems, I show how principled abstractions enable practitioners to directly express and compose their intentions, bridging the gap from intent to reality. 